# -*- coding: utf-8 -*-
"""Cliniscan17.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BcgF6bY0tJDKM0zu4e7nLyljuvqVJ31X

**CliniScan:Lung-Abnormality Detection on Chest X‚Äërays using AI**

**1-DICOM to PNG Conversion Utility**
"""

# Commented out IPython magic to ensure Python compatibility.
# Install dependencies
# %pip install pydicom
!pip install grad-cam
import os
import cv2
import pydicom
import pandas as pd


def dicom_to_png(dicom_path: str, png_path: str) -> bool:
    """Convert a single DICOM file to PNG format."""
    try:
        ds = pydicom.dcmread(dicom_path)
        img = ds.pixel_array

        # Normalize pixel values to 0‚Äì255 and convert to uint8
        img_norm = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX)
        img_uint8 = img_norm.astype("uint8")

        cv2.imwrite(png_path, img_uint8)
        return True
    except Exception as e:
        print(f"‚ùå Failed to convert {dicom_path}: {e}")
        return False


def convert_dataset(dicom_dir: str, output_dir: str, annotations_csv: str):
    """Batch convert DICOM dataset to PNG using annotations."""
    os.makedirs(output_dir, exist_ok=True)
    annotations = pd.read_csv(annotations_csv)

    for _, row in annotations.iterrows():
        dicom_file = os.path.join(dicom_dir, f"{row['image_id']}.dicom")
        png_file = os.path.join(output_dir, f"{row['image_id']}.png")

        if os.path.exists(dicom_file):
            if dicom_to_png(dicom_file, png_file):
                print(f"‚úÖ Converted: {dicom_file} ‚Üí {png_file}")
        else:
            print(f"‚ö†Ô∏è Missing file: {dicom_file}")

"""**2-Custom Dataset Class (VinDr-CXR)**"""

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
import pandas as pd
import numpy as np
import cv2
from PIL import Image

class VinDrCXRDataset(Dataset):
    def __init__(self, df, img_dir, transform=None, task='classification'):
        self.df = df
        self.img_dir = img_dir
        self.transform = transform
        self.task = task

        self.labels = sorted(df['label'].unique())
        self.label_to_id = {label: i for i, label in enumerate(self.labels)}

        self.grouped_images = self.df.groupby('image_id')
        self.image_ids = list(self.grouped_images.groups.keys())

    def __len__(self):
        return len(self.image_ids)

    def __getitem__(self, idx):
        img_id = self.image_ids[idx]
        img_path = os.path.join(self.img_dir, f"{img_id}.png")
        image = Image.open(img_path).convert("RGB")
        annotations = self.grouped_images.get_group(img_id)

        if self.task == 'classification':
            label_vector = torch.zeros(len(self.labels), dtype=torch.float)
            for _, row in annotations.iterrows():
                label_vector[self.label_to_id[row['label']]] = 1.0

            if self.transform:
                image = self.transform(image)

            return image, label_vector

        elif self.task == 'detection':
            boxes, labels = [], []
            for _, row in annotations.iterrows():
                boxes.append([row['x_min'], row['y_min'], row['x_max'], row['y_max']])
                labels.append(self.label_to_id[row['label']])

            target = {
                'boxes': torch.tensor(boxes, dtype=torch.float32),
                'labels': torch.tensor(labels, dtype=torch.int64)
            }

            if self.transform:
                image = self.transform(image)

            return image, target

"""**3-ResNet18 Classifier (Transfer Learning)**"""

import torch
import torch.nn as nn
from torchvision.models import resnet18, ResNet18_Weights

class ResNetClassifier(nn.Module):
    def __init__(self, num_classes):
        super(ResNetClassifier, self).__init__()
        # Load a pre-trained ResNet-18 model
        self.model = resnet18(weights=ResNet18_Weights.DEFAULT)
        # Modify the final fully connected layer for your number of classes
        num_ftrs = self.model.fc.in_features
        self.model.fc = nn.Linear(num_ftrs, num_classes)

    def forward(self, x):
        return self.model(x)

if __name__ == "__main__":
    num_classes = 5 # Example number of classes
    model = ResNetClassifier(num_classes)

    # Check model output
    dummy_input = torch.randn(1, 3, 256, 256)
    output = model(dummy_input)
    print(f"Model output shape: {output.shape}")

"""**4.Google Drive Mount & Dataset Extraction**"""

import zipfile, os
from google.colab import drive

# Mount Google Drive
drive.mount('/content/drive', force_remount=True)

zip_path = "/content/drive/MyDrive/ColabDatasets/archive(3).zip"
extract_path = "/content/dataset"

# Extract dataset if not already extracted
if not os.path.exists(extract_path) or not os.listdir(extract_path):
    os.makedirs(extract_path, exist_ok=True)
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extract_path)
    print(f"‚úÖ Dataset extracted to: {extract_path}")
else:
    print(f"‚ÑπÔ∏è Dataset already exists at: {extract_path}")

# Show dataset structure (first 40 lines)
print("üìÇ Dataset structure (first 40 lines):")
!ls -R /content/dataset | head -40

"""**5-YOLOv8 Setup, Dataset Preparation & Training**"""

# Install YOLOv8
!pip install ultralytics --quiet

import os
import random
import torch
import zipfile
import shutil
from ultralytics import YOLO
from google.colab import drive

# Check PyTorch & GPU
print("‚úÖ Torch version:", torch.__version__)
print("‚úÖ GPU available:", torch.cuda.is_available())
if torch.cuda.is_available():
    print("‚úÖ GPU name:", torch.cuda.get_device_name(0))

# Mount Google Drive
drive.mount('/content/drive', force_remount=True)

# Dataset paths
zip_path = "/content/drive/MyDrive/ColabDatasets/archive(3).zip"
extract_path = "/content/dataset"

# Extract dataset if not already extracted
if not os.path.exists(extract_path) or not os.listdir(extract_path):
    os.makedirs(extract_path, exist_ok=True)
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extract_path)
    print(f"‚úÖ Dataset extracted to {extract_path}")
else:
    print("‚ÑπÔ∏è Dataset already available.")

# Reorganize dataset for YOLOv8 classification (example: single class 'cat')
train_dir = os.path.join(extract_path, "train")
val_dir = os.path.join(extract_path, "val")

cat_train_dir = os.path.join(train_dir, "cat")
os.makedirs(cat_train_dir, exist_ok=True)

# Move all training images into class folder
for f in os.listdir(train_dir):
    if f.lower().endswith(('.jpg', '.jpeg', '.png')):
        shutil.move(os.path.join(train_dir, f), os.path.join(cat_train_dir, f))

# Create validation directory and subfolder
os.makedirs(val_dir, exist_ok=True)
cat_val_dir = os.path.join(val_dir, "cat")
os.makedirs(cat_val_dir, exist_ok=True)

# Split 10% of data into validation
images = os.listdir(cat_train_dir)
random.shuffle(images)
num_val = max(1, int(0.1 * len(images)))

for img in images[:num_val]:
    shutil.move(os.path.join(cat_train_dir, img), os.path.join(cat_val_dir, img))

print("‚úÖ Dataset reorganized for YOLOv8 classification.")

# Show dataset structure (first 40 lines)
!ls -R /content/dataset | head -40

# Load pretrained YOLOv8 classification model
model = YOLO("yolov8n-cls.pt")

# Train the model
model.train(
    data="/content/dataset/chest_xray/chest_xray",  # path with train/ and val/
    epochs=20,
    imgsz=224,
    batch=32,
    name="classification_model_fixed"
)

"""**6-Grad-CAM Setup & Visualization**"""

# ===================================================================
# X-RAY PREDICTION + GRAD-CAM VISUALIZATION
# ===================================================================
import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
from torchvision import transforms
from PIL import Image

from pytorch_grad_cam import GradCAM
from pytorch_grad_cam.utils.image import show_cam_on_image
from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget

# -----------------------------
# Load your model
# -----------------------------
from __main__ import ResNetClassifier  # replace if needed

num_classes = 2   # NORMAL, PNEUMONIA
class_names = ["NORMAL", "PNEUMONIA"]

model = ResNetClassifier(num_classes)
# model.load_state_dict(torch.load("model.pth", map_location="cpu"))  # uncomment when trained model is available
model.eval()

# -----------------------------
# Preprocessing
# -----------------------------
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])

# -----------------------------
# Prediction + Grad-CAM Function
# -----------------------------
def predict_and_visualize(image_path):
    # Load and preprocess
    img = Image.open(image_path).convert("RGB")
    input_tensor = transform(img).unsqueeze(0)

    # Original image for overlay
    rgb_img = np.array(img.resize((224, 224))) / 255.0

    # Forward pass
    with torch.no_grad():
        outputs = model(input_tensor)
        probs = torch.softmax(outputs, dim=1)[0]

    pred_class = torch.argmax(probs).item()
    confidence = probs[pred_class].item() * 100

    print(f"Predicted class: {class_names[pred_class]} ({confidence:.2f}%)")

    # -------------------------
    # Grad-CAM
    # -------------------------
    target_layers = [model.model.layer4[-1]]  # last conv block
    cam = GradCAM(model=model, target_layers=target_layers)
    grayscale_cam = cam(input_tensor=input_tensor,
                        targets=[ClassifierOutputTarget(pred_class)])[0]
    cam_image = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)

    # -------------------------
    # Plot Results
    # -------------------------
    fig, axes = plt.subplots(1, 3, figsize=(18, 6))

    # Original Image
    axes[0].imshow(rgb_img)
    axes[0].set_title("Original Image")
    axes[0].axis("off")

    # Grad-CAM
    axes[1].imshow(cam_image)
    axes[1].set_title(f"Grad-CAM Heatmap ({class_names[pred_class]})")
    axes[1].axis("off")

    # Probability Distribution
    axes[2].bar(class_names, probs.numpy() * 100, color=["green", "red"])
    axes[2].set_ylabel("Probability (%)")
    axes[2].set_title("Prediction Probabilities")

    plt.tight_layout()
    plt.show()

    return class_names[pred_class], confidence

# -----------------------------
# Example Run
# -----------------------------
image_path = "/content/dataset/chest_xray/chest_xray/train/NORMAL/IM-0129-0001.jpeg"
predict_and_visualize(image_path)

"""**7-Deployment**"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import torch
# import torch.nn as nn
# from torchvision import transforms, models
# from PIL import Image
# import subprocess
# import threading
# import time
# import os
# from pyngrok import ngrok, conf
# 
# # ================================================================
# # Deployment Setup (Streamlit + ngrok)
# # ================================================================
# STREAMLIT_PORT = 8501
# NGROK_AUTH_TOKEN = "YOUR_NGROK_AUTH_TOKEN"  # Replace with your token
# 
# def start_streamlit_process():
#     """Run Streamlit app as background process."""
#     cmd = ["streamlit", "run", "app.py", "--server.port", str(STREAMLIT_PORT), "--server.headless=True"]
#     proc = subprocess.Popen(cmd)
#     return proc
# 
# def start_ngrok_tunnel(port):
#     """Create ngrok tunnel for given port."""
#     try:
#         if NGROK_AUTH_TOKEN == "YOUR_NGROK_AUTH_TOKEN":
#             print("\n--- NGROK SETUP FAILED ---")
#             print("Set your ngrok auth token in NGROK_AUTH_TOKEN.")
#             return None
#         conf.get_default().auth_token = NGROK_AUTH_TOKEN
#         public_url = ngrok.connect(port, proto="http")
#         return public_url
#     except Exception as e:
#         print(f"Failed to start ngrok tunnel: {e}")
#         return None
# 
# # Run deployment if not already in Streamlit
# if "RUNNING_IN_STREAMLIT" not in os.environ:
#     os.environ["RUNNING_IN_STREAMLIT"] = "true"
#     print("\n--- Starting Deployment ---")
# 
#     threading.Thread(target=start_streamlit_process).start()
#     time.sleep(5)  # wait for Streamlit
#     public_url = start_ngrok_tunnel(STREAMLIT_PORT)
# 
#     if public_url:
#         print("\n--- APP DEPLOYED ---")
#         print(f"Public URL: {public_url}\n")
#         print("Press Ctrl+C to stop.")
# 
#     try:
#         while True:
#             time.sleep(1)
#     except KeyboardInterrupt:
#         print("\nShutting down...")
#         ngrok.kill()
#         print("Done.")
#     st.stop()
# 
# # ================================================================
# # Streamlit App Logic
# # ================================================================
# 
# # --- Load Model ---
# @st.cache_resource
# def load_model():
#     """Load trained model or dummy ResNet."""
#     model = models.resnet18(pretrained=False)
#     model.fc = nn.Linear(model.fc.in_features, 2)
#     try:
#         model.load_state_dict(torch.load("model.pth", map_location="cpu"))
#         st.success("Trained model loaded.")
#     except FileNotFoundError:
#         st.warning("`model.pth` not found. Using dummy model.")
#     model.eval()
#     return model
# 
# model = load_model()
# 
# # --- Preprocessing ---
# transform = transforms.Compose([
#     transforms.Resize((224, 224)),
#     transforms.ToTensor(),
#     transforms.Normalize([0.485, 0.456, 0.406],
#                          [0.229, 0.224, 0.225])
# ])
# 
# # --- User Interface ---
# st.title("ü©ª Chest X-Ray Classification")
# st.write("Upload a Chest X-ray image for classification.")
# 
# uploaded_file = st.file_uploader("Upload an image", type=["jpg", "jpeg", "png"])
# 
# if uploaded_file:
#     try:
#         image = Image.open(uploaded_file).convert("RGB")
#         st.image(image, caption="Uploaded Image", use_column_width=True)
# 
#         input_tensor = transform(image).unsqueeze(0)
#         with torch.no_grad():
#             outputs = model(input_tensor)
#             probs = torch.softmax(outputs, dim=1)[0]
#             pred_class = torch.argmax(probs).item()
# 
#         class_names = ["Normal", "Pneumonia"]
#         st.write(f"### Prediction: **{class_names[pred_class]}**")
#         st.write(f"Confidence: {probs[pred_class].item()*100:.2f}%")
#         st.bar_chart({class_names[i]: probs[i].item() for i in range(len(class_names))})
#     except Exception as e:
#         st.error(f"Prediction error: {e}")
#

!python app.py

!jupyter nbconvert --to script your_notebook.ipynb